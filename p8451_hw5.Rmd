---
title: "Machine Learning for Epi: Assignment 5"
output:
  html_document: default
  word_document: default
date: "2023-02-21"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      warning = F,
                      message = F)

library(tidyverse)
library(caret)
library(klaR)
library(glmnet)
```

## Description of Data

The data we will be using are from the online survey related to drug and alcohol use and personality traits. These data were collected as part of an online survey related to drug and alcohol use and personality traits from the UCI Machine Learning Repository. *We will be using this dataset to try to identify the most important behavioral predictors of alcohol consumption.* We have restricted the dataset to 7 features and an outcome which distinguishes those who reported current alcohol use (defined as alcohol use in the past month or more frequently) vs no current use. 

### Step 1: Load data and prepare for analysis

The code chunk below loads the Alcohol Consumption survey data and strips the id variable, omits missing observations, and converts the outcome variable, `alc_consumption` to a factor variable. 

```{r load_data}
alcohol_use = readr::read_csv("./alcohol_use.csv") %>% 
  mutate(alc_consumption = as.factor(alc_consumption), 
         alc_consumption = fct_relevel(alc_consumption, c("NotCurrentUse", "CurrentUse"))) %>% 
  dplyr::select(-`...1`) %>% 
  drop_na()  
  
summary(alcohol_use) %>% knitr::kable(digits = 2)
```

Our resulting variables include 7 behavioral/personality scores, which are numeric, and our binary outcome variable, `alc_consumption`. Based on the summary, we can see that the distribution is similar across the numeric variables, and appears to be already scaled and centered. Therefore, will skip the centering and scaling steps in pre-processing.

### Step 2: Partition the data 

The code chunk below partitions the data into training and testing sets, using a 70/30 split. 

```{r partition_data}
set.seed(123)

#Creating balanced partitions in the data
train_index = createDataPartition(alcohol_use$alc_consumption, p = 0.7, list = FALSE)

alc_train = alcohol_use[train_index,]
alc_test = alcohol_use[-train_index,]

#Check distribution of the outcome between train and test data
summary(alc_train$alc_consumption) 
summary(alc_test$alc_consumption)
```

We can see that there are similar distributions of the variable `alc_consumption`, with approximately 53% of cases of alcohol use across both the training and testing sets, indicating that the data were successfully partitioned.

### Step 3: Construct logistic regression models to predict healthy days

We will fit 3 regularized and traditional logistic models to predict current alcohol consumption. (feature name: `alc_consumption`).

- Model 1 (`mod_elastic`): An elastic net model based on all features, using cross-validation to choose alpha and lambda.

- Model 2 (`mod_baseline`): An traditional logistic model based on all features, serving as our 'baseline model'.

- Model 3 (`mod_lasso`): A LASSO logistic model based on all features.

#### Elastic Net Model

To fit the elastic net model, we will train using 10-fold cross-validation, and set the tune length to 10 combinations of alpha and lambda to train on.

```{r mod_elastic}
set.seed(123)

mod_elastic = train(alc_consumption ~ ., data = alc_train, method = "glmnet", 
                 trControl = trainControl("cv", number = 10), 
                 tuneLength = 10)
#Print the values of alpha and lambda that gave best prediction
mod_elastic$bestTune

# Model coefficients
coef(mod_elastic$finalModel, mod_elastic$bestTune$lambda)
```

The resulting model found an optimal \alpha of 0.6 and \lambda of 0.263. We can see that the features selected to be included in the model are Impulsivity and Sensation-Seeking Behaviors.

#### Logistic Regression Model

To fit the elastic net model, we will train using 10-fold cross-validation.

```{r mod_logistic}
set.seed(123)

mod_baseline = train(alc_consumption ~ ., data = alc_train, method = "glm", 
                 trControl = trainControl("cv", number = 10))

coef(mod_baseline$finalModel)
```

The resulting model includes all features to be fed into the model, with Impulsivity and Sensation-Seeking Behaviors having the largest effect size as indicated by the magnitude of their coefficients.

#### LASSO Model

To fit the elastic net model, we will train using 10-fold cross-validation, and fix alpha to 1. We then create a search grid of 100 to search for the optimal lambda value. 

```{r mod_LASSO}
set.seed(123)

#Create grid to search lambda
lambda = 10^seq(-3, 3, length = 100)

#Fit model with tuneGrid
mod_lasso = train(alc_consumption ~ ., data = alc_train, method = "glmnet", 
                  trControl = trainControl("cv", number = 10), tuneGrid = expand.grid(alpha = 1, lambda = lambda))

#Print the values of alpha and lambda that gave best prediction
mod_lasso$bestTune

# Model coefficients
coef(mod_lasso$finalModel, mod_lasso$bestTune$lambda)
```

The resulting model found an optimal \lambda of 0.231. We can see that there was only 1 feature, Impulsivity, that was selected to be in the model.

### Step 4: Model Evaluation

Next, to determine the preferred prediction model, we will apply both models to make predictions in the test data. We will use the `confusionMatrix()` function to get performance measures of accuracy, kappa, sensitivity, specificity, and precision (PPV) for each candidate model.

```{r test_EN}
## ELASTIC MODEL
# Make predictions in test set
en_pred = mod_elastic %>% predict(alc_test)
alc_test = alc_test %>% mutate(en_pred = as.factor(en_pred))

# Model prediction performance
cm_EN = confusionMatrix(data = alc_test$en_pred, reference = alc_test$alc_consumption, positive = "CurrentUse")

EN_perf = cbind(cm_EN$overall %>% as_tibble_row(), cm_EN$byClass %>% as_tibble_row()) %>% 
  dplyr::select(Accuracy, Kappa, Sensitivity, Specificity, Precision)
```

```{r test_baseline}
## LOGISTIC REG MODEL
# Make predictions in test set
logmod_pred = mod_baseline %>% predict(alc_test)
alc_test = alc_test %>% mutate(logmod_pred = as.factor(logmod_pred))

# Model prediction performance
cm_log = confusionMatrix(data = alc_test$logmod_pred, reference = alc_test$alc_consumption, positive = "CurrentUse")

log_perf = cbind(cm_log$overall %>% as_tibble_row(), cm_log$byClass %>% as_tibble_row()) %>% 
  dplyr::select(Accuracy, Kappa, Sensitivity, Specificity, Precision)
```

```{r test_LASSO}
## ELASTIC MODEL
# Make predictions in test set
lasso_pred = mod_lasso %>% predict(alc_test)
alc_test = alc_test %>% mutate(lasso_pred = as.factor(lasso_pred))

# Model prediction performance
cm_LASSO = confusionMatrix(data = alc_test$lasso_pred, reference = alc_test$alc_consumption, positive = "CurrentUse")

LASSO_perf = cbind(cm_LASSO$overall %>% as_tibble_row(), cm_LASSO$byClass %>% as_tibble_row()) %>% 
  dplyr::select(Accuracy, Kappa, Sensitivity, Specificity, Precision)
```

#### Comparing performance across models

Finally, let's compare the performance of the 3 models.

```{r compare}
rbind(EN_perf, log_perf, LASSO_perf) %>% 
  mutate(Model = c("Elastic Net", "Baseline", "LASSO")) %>% 
  relocate(Model, .before = Accuracy) %>% knitr::kable(digits = 4)
```

The table shows that the elastic net and LASSO models have the same accuracy of 83.19%, outperforming the baseline model's accuracy of 80.35%. We see that the performance of elastic net and LASSO are also the same in terms of sensitivity, specificity, and precision. While the baseline model has a slightly lower accuracy, there is slightly better trade-off between specificity and sensitivity, resulting in a higher specificity, as well as improved precision. However, if I was interested in making sure I detect all cases of current alcohol use, I would go with the LASSO model, as it is a more parsimonious (simpler) model with 1 feature compared to the elastic net model with 2 features, while having the same predictive performance.


### Research Applications

This analysis could directly address the research question of which behavioral features best predict current alcohol consumption, and therefore narrow down the list of behavioral tests clinicians may need to administer to patients in order to carry out this predictive task. One such application could be applying this predictive model to patients' electronic health records to predict current alcohol consumption among patients on the basis of behavioral test scores.
